<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Dimensions of Machine Usefulness in Science - Pendentive Consulting</title>
    <link rel="icon" type="image/png" href="images/favicon.png">
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Sans:wght@100;400;500;600&family=IBM+Plex+Mono:wght@400;500&display=swap" rel="stylesheet">
    <link rel="stylesheet" href="css/styles.css">
</head>
<body>
    <header>
        <div class="container">
            <a href="index.html" class="logo">
                <img src="images/logo-dark.png" alt="Pendentive logo">
                Pendentive
            </a>
            <nav>
                <a href="writing.html" class="active">Writing</a>
                <a href="reading.html">Reading</a>
            </nav>
        </div>
    </header>

    <main>
        <article>
            <div class="article-header">
                <div class="container">
                    <a href="writing.html" class="back-link">&larr; Back to Writing</a>
                    <h1>Dimensions of Machine Usefulness in Science</h1>
                    <p class="subtitle">A framework for evaluating AI-enabled science by human capability expansion</p>
                </div>
            </div>

            <div class="article-content">
                <div class="container">
                    <h3>Acemoglu and Johnson on Machine Usefulness</h3>

                    <p>In <em>Power and Progress: Our Thousand-Year Struggle Over Technology and Prosperity</em> (2023), economists Daron Acemoglu and Simon Johnson argue that technological progress does not automatically produce broad-based prosperity. What matters is <em>how</em> technologies are deployed. They distinguish between genuinely useful technologies—which augment human capabilities, create new tasks for humans to perform, and generate productivity gains that flow broadly—and "so-so automation," which displaces workers without creating commensurate new value. Self-checkout kiosks are their canonical example: they eliminate cashier jobs but don't dramatically improve the shopping experience, primarily shifting labor costs from corporations to customers while degrading service quality. The question for any new technology is not "can it replace human labor?" but "does it expand what humans can do, and who benefits?"</p>

                    <h3>The Problem with Autonomy Frameworks</h3>

                    <p>Existing frameworks for self-driving laboratories measure progress by how much human involvement can be removed. The highest levels describe labs where humans "merely serve the needs" of the machine or "set a research direction" and walk away.</p>

                    <p>These frameworks share two questionable assumptions:</p>

                    <p><strong>First, they conflate technical achievement with value creation.</strong> "Can the machine do this without human intervention?" is a different question from "Does this advance science, create new human capabilities, or generate broad-based benefit?" History suggests technologies that maximize human displacement often create what Acemoglu and Johnson call "so-so automation"—systems that substitute for human labor at roughly equivalent performance while redistributing value rather than creating it.</p>

                    <p><strong>Second, they impose false linearity.</strong> Autonomy frameworks present progress as a single journey from Level 0 to Level 5, where each stage subsumes the previous. But the actual landscape of useful scientific tools is multidimensional. SnapGene—software that externalizes and disciplines molecular biologists' reasoning about DNA constructs—is enormously valuable without being "higher" on any autonomy scale. It's not "Level 2" waiting to become "Level 4." It's excellent along dimensions that autonomy frameworks don't measure at all.</p>

                    <p>This framework proposes an alternative: measuring AI-enabled science by the <strong>new human capabilities it creates</strong>, not the human tasks it eliminates—and recognizing that these capabilities vary along multiple independent dimensions, not a single axis.</p>

                    <hr>

                    <h2>The Six Dimensions of Machine Usefulness in Science</h2>

                    <p>A tool may score high on some dimensions and low on others. There is no implied progression—excellence along one dimension does not require or lead to excellence along others.</p>

                    <h3>1. Friction Reduction</h3>

                    <p><strong>Can we do the same work with less effort?</strong></p>

                    <h4>Characteristics:</h4>
                    <ul>
                        <li>Scientists do the same work, but with less friction</li>
                        <li>Primary value: time savings, reduced drudgery</li>
                        <li>Human judgment remains central to all decisions</li>
                    </ul>

                    <h4>Examples:</h4>
                    <ul>
                        <li>Automated pipetting that executes human-designed protocols</li>
                        <li>Data visualization tools that format results for human interpretation</li>
                        <li>Literature search that surfaces relevant papers faster</li>
                    </ul>

                    <p><em>Evaluation question:</em> Would removing this tool change <em>what</em> science gets done, or just <em>how fast</em>?</p>

                    <p><em>Risk:</em> Can become so-so automation if it primarily displaces workers without enabling new science.</p>

                    <hr>

                    <h3>2. Reach Extension</h3>

                    <p><strong>Can we access experimental territory that was previously impractical?</strong></p>

                    <h4>Characteristics:</h4>
                    <ul>
                        <li>Scientists can now do things that were previously impractical</li>
                        <li>Opens new experimental territory rather than accelerating existing work</li>
                        <li>Human judgment guides direction; machine extends reach</li>
                    </ul>

                    <h4>Examples:</h4>
                    <ul>
                        <li>High-throughput screening that makes combinatorial exploration feasible</li>
                        <li>Robotic manipulation of hazardous or extreme-condition samples</li>
                        <li>Continuous monitoring that captures dynamics humans would miss</li>
                    </ul>

                    <p><em>Evaluation question:</em> Are scientists asking questions they wouldn't have asked before?</p>

                    <p><em>Value creation:</em> New experimental territory creates new opportunities for insight, new specializations, new translational pathways—new human tasks.</p>

                    <hr>

                    <h3>3. Pattern Surfacing</h3>

                    <p><strong>Can we perceive structures we couldn't see before?</strong></p>

                    <h4>Characteristics:</h4>
                    <ul>
                        <li>Identifies patterns, correlations, or anomalies across scales humans can't process</li>
                        <li>Outputs require human interpretation to become knowledge</li>
                        <li>Creates new objects for human reasoning</li>
                    </ul>

                    <h4>Examples:</h4>
                    <ul>
                        <li>Dimensionality reduction revealing clusters in high-dimensional data</li>
                        <li>Anomaly detection flagging unexpected results for human investigation</li>
                        <li>Cross-dataset integration connecting disparate findings</li>
                    </ul>

                    <p><em>Evaluation question:</em> Does this generate hypotheses that surprise domain experts?</p>

                    <p><em>Value creation:</em> New patterns create new questions, new subfields, new interpretive expertise—humans become specialists in making sense of machine-surfaced structure.</p>

                    <hr>

                    <h3>4. Repertoire Expansion</h3>

                    <p><strong>Can we access expertise that was previously siloed or tacit?</strong></p>

                    <h4>Characteristics:</h4>
                    <ul>
                        <li>Aggregates expertise that no single human possesses</li>
                        <li>Makes implicit knowledge explicit and executable</li>
                        <li>Enables non-experts to leverage expert-level protocols</li>
                    </ul>

                    <h4>Examples:</h4>
                    <ul>
                        <li>LLM-assisted protocol generation drawing on literature-wide best practices</li>
                        <li>Cross-domain suggestion systems (e.g., recombinase biochemistry &rarr; cloning optimization)</li>
                        <li>Troubleshooting assistants encoding accumulated lab wisdom</li>
                    </ul>

                    <p><em>Evaluation question:</em> Can a competent scientist now do what previously required rare specialized expertise?</p>

                    <p><em>Value creation:</em> Democratizes capability, lowers barriers to entry, creates demand for new integrative roles (people who can combine newly-accessible techniques in novel ways). The human task shifts from <em>possessing</em> rare expertise to <em>combining</em> newly-accessible capabilities.</p>

                    <hr>

                    <h3>5. Judgment Amplification</h3>

                    <p><strong>Can we make better decisions under complexity?</strong></p>

                    <h4>Characteristics:</h4>
                    <ul>
                        <li>Handles complexity, uncertainty, or scale beyond human cognitive limits</li>
                        <li>Human values, priorities, and risk tolerance remain upstream</li>
                        <li>Machine provides decision support, not decision replacement</li>
                    </ul>

                    <h4>Examples:</h4>
                    <ul>
                        <li>Experimental design optimization under complex constraints</li>
                        <li>Uncertainty quantification that makes honest confidence intervals tractable</li>
                        <li>Scenario modeling that reveals consequences of strategic choices</li>
                    </ul>

                    <p><em>Evaluation question:</em> Are scientists making <em>better</em> decisions, or just <em>faster</em> ones?</p>

                    <p><em>Value creation:</em> Creates demand for humans skilled in specifying values, interpreting tradeoffs, and exercising judgment at higher levels of abstraction. The hard problems remain human problems.</p>

                    <hr>

                    <h3>6. Cognitive Scaffolding</h3>

                    <p><strong>Can we reason more reliably and share that reasoning?</strong></p>

                    <h4>Characteristics:</h4>
                    <ul>
                        <li>Externalizes and disciplines human reasoning</li>
                        <li>Makes thinking visible, revisable, and transmissible</li>
                        <li>Prevents errors by structuring cognition, not by replacing it</li>
                    </ul>

                    <h4>Examples:</h4>
                    <ul>
                        <li>SnapGene: visualization and planning tools that ensure scientists know the full properties of the DNA they're working with</li>
                        <li>Electronic lab notebooks that create records as a byproduct of planning</li>
                        <li>Version control systems that make the history of reasoning accessible</li>
                    </ul>

                    <p><em>Evaluation question:</em> Does this make individual reasoning more robust <em>and</em> make that reasoning shareable across people and time?</p>

                    <p><em>Value creation:</em> Knowledge accumulates rather than dissipating. Errors get caught earlier. Expertise becomes teachable. The human task shifts from <em>remembering</em> to <em>reasoning</em>.</p>

                    <hr>

                    <h2>How This Framework Differs</h2>

                    <table class="comparison-table">
                        <thead>
                            <tr>
                                <th>Dimension</th>
                                <th>Autonomy Frameworks</th>
                                <th>Machine Usefulness Framework</th>
                            </tr>
                        </thead>
                        <tbody>
                            <tr>
                                <td>Structure</td>
                                <td>Linear levels (0&rarr;5)</td>
                                <td>Independent dimensions</td>
                            </tr>
                            <tr>
                                <td>Measures progress by</td>
                                <td>Human removal</td>
                                <td>Human capability expansion</td>
                            </tr>
                            <tr>
                                <td>Ideal end state</td>
                                <td>Machine "in charge"</td>
                                <td>Humans doing things previously impossible</td>
                            </tr>
                            <tr>
                                <td>Treats human involvement as</td>
                                <td>Limitation to minimize</td>
                                <td>Source of value to cultivate</td>
                            </tr>
                            <tr>
                                <td>Success criterion</td>
                                <td>Can it run without us?</td>
                                <td>Can we do more with it?</td>
                            </tr>
                            <tr>
                                <td>Economic model</td>
                                <td>Substitution</td>
                                <td>Complementarity</td>
                            </tr>
                            <tr>
                                <td>Evaluates tools by</td>
                                <td>Position on single axis</td>
                                <td>Profile across multiple dimensions</td>
                            </tr>
                        </tbody>
                    </table>

                    <hr>

                    <h2>Implications for Investment and Policy</h2>

                    <h3>Favor complementarity over substitution</h3>
                    <p>Prioritize systems where human and machine capabilities are genuinely different and mutually enabling, not where machines do what humans do slightly better.</p>

                    <h3>Beware throughput metrics</h3>
                    <p>"10x more experiments" is only valuable if the experiments are worth running. Throughput divorced from insight is infrastructure, not progress.</p>

                    <h3>Invest in translation layers</h3>
                    <p>The specification bottleneck—translating human intent into machine-executable instructions—is where the most leverage likely lies. Natural language interfaces, better protocol languages, and intent-to-execution pipelines create capability broadly.</p>

                    <h3>Fund the interpretive infrastructure</h3>
                    <p>As machines surface more patterns, the bottleneck shifts to human sense-making. Invest in visualization, explanation, and education alongside automation.</p>

                    <h3>Ask distributional questions</h3>
                    <p>Who benefits? If primarily capital owners and elite institutions, the case for public investment weakens. If early-career scientists, under-resourced labs, and patients, the case strengthens.</p>

                    <hr>

                    <h2>Conclusion</h2>

                    <p>The autonomy framing asks: "How much can we remove the human?" and measures progress along a single axis from full human involvement to full machine control.</p>

                    <p>The machine usefulness framing asks: "How much more can the human do?" and recognizes that capability expansion happens along multiple independent dimensions. A tool like SnapGene can be transformative without being "autonomous" at all. An LLM conversation can provide Repertoire Expansion and Cognitive Scaffolding without Reach Extension or Judgment Amplification.</p>

                    <p>This reframing matters because it changes what we optimize for. The autonomy framing risks creating sophisticated infrastructure that concentrates benefit and displaces workers without commensurate productivity gains—so-so automation dressed up as progress. The machine usefulness framing aims for technologies that expand human capability, create new tasks, and generate broad-based benefit.</p>

                    <p>The best AI-enabled science will be measured not by how autonomous the lab becomes, but by what scientists—and ultimately, all of us—can do that we couldn't do before.</p>
                </div>
            </div>
        </article>
    </main>

    <footer>
        <div class="container">
            <p>&copy; 2025 Pendentive Consulting &middot; Richmond, VA</p>
        </div>
    </footer>
</body>
</html>
